<!DOCTYPE html><html lang="ja-JP"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Core"><link rel="icon" href="/images/favicon.ico" type="image/x-icon"><title>ディープラーニング Caffe for Windows その2 指紋紋様分類 · A certain engineer "COMPLEX"</title><meta name="description" content="前回は環境を構築してみました、

指紋指紋といえば、ごく一部の人間を覗いて全ての人間が手にもっている隆線によって形成される紋様です。指紋を持っていない人間もごく一部に存在しますが…
iPhoneのTouchIDで急激に認知度が向上した気がします。特に日本では、指紋の採取というのは、人権団体とかの声と"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/blogcard.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.1.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.webp" style="width:127px;"><h3 title=""><a href="/">A certain engineer &quot;COMPLEX&quot;</a></h3><div class="description"><p>とある技術者の劣等感</p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi"><i class="fa fa-github"></i></a></li><li><a target="_blank" rel="noopener" href="https://twitter.com/takuya_takeuchi"><i class="fa fa-twitter-square"></i></a></li><li><a target="_blank" rel="noopener" href="https://www.facebook.com/takuya.takeuchi.sns"><i class="fa fa-facebook-square"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2020 </span><i class="fa fa-star"></i><span> Core</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="search"><div class="text"><input placeholder="検索ワードを入力してください" id="search-text" onkeypress="javascript:search(event)"></div><div class="btn"><a><i class="fa fa-search"></i></a></div></div><div class="nav"><li><a href="/">ホーム</a></li><li><a href="/archives">アーカイブ</a></li><li><a href="/tags">タグ</a></li><li><a href="/about">自己紹介</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>ディープラーニング Caffe for Windows その2 指紋紋様分類</a></h3></div><div class="post-content"><p><a target="_blank" rel="noopener" href="https://taktak.jp/2016/05/28/1372">前回</a>は環境を構築してみました、</p>
<a id="more"></a>
<h1 id="指紋"><a href="#指紋" class="headerlink" title="指紋"></a>指紋</h1><p>指紋といえば、ごく一部の人間を覗いて全ての人間が手にもっている隆線によって形成される紋様です。<br>指紋を持っていない人間もごく一部に存在しますが…</p>
<p><strong>iPhone</strong>の<strong>TouchID</strong>で急激に認知度が向上した気がします。<br>特に日本では、指紋の採取というのは、人権団体とかの声とかプライバシー云々でいまいち悪のレッテルを貼られている感が否めません。</p>
<p>さて、指紋は古くから使われており、個人を識別する徴として、日本では拇印としてよく知られています。<br>個人を識別するだけなら、指紋以外に、虹彩、静脈、顔が有名です。<br>他にも掌紋、足紋もあります。</p>
<h3 id="生体認証"><a href="#生体認証" class="headerlink" title="生体認証"></a>生体認証</h3><p>この手の生物に備わる生体の特徴に基づいた認証を<strong>生体認証 (Biometrics)</strong> と呼びます。<br>指掌紋技術では、たくさんの企業が競争していますが、<strong>3M Cogent (アメリカ)**、</strong>Morpho (フランス)<strong>、</strong>NEC (日本)<strong>が三強です。<br>ここでいう三強とは、司法機関、入国管理など、大規模システムでの納入実績が大きい企業を指します。<br>(例えば、ロサンゼルス国際空港では、Morphoの指紋採取機器が入国管理ゲートにありますし、成田空港にはNECの指紋採取機器があります。) iPhoneの場合、</strong>Apple<strong>は</strong>AuthenTec社**を買収して、TouchIDを開発したようですが、これは指紋を読み取る機器の買収がメインだったと思われます。<br>指紋の採取の場合、光学センサーで読み取るのが主流ですが、AuthenTec社の場合は周波数で読み取るセンサーだったようで、それがiPhoneでの採用に繋がったのでしょう。</p>
<p>ですので、三強にAppleがない、というのは別に悪意があるわけではなく、この三強は、大規模システム、たとえば、数千万の指紋データから瞬時に個人を特定するなどの総合的な技術を持っています。TouchIDの場合、iPhoneに含まれる指紋データは一人のデータでかつ最大10本の指データです。大して大規模システムでは、入力指紋、つまり識別したい指紋1に対して候補となる指紋データは数千万にも上ることもあります。<br>事実、アメリカ国立標準技術研究所 (National Institute of Standards and Technology, NIST) の指掌紋技術コンテストでは、計測する内容にもよりますが、上位はこの三強が常です。</p>
<p><a target="_blank" rel="noopener" href="http://jpn.nec.com/press/201408/20140821_02.html">NEC、米国国立標準技術研究所(NIST)の指紋認証技術のベンチマークテストにおいて第1位の評価を獲得</a> <a target="_blank" rel="noopener" href="http://www.morpho.com/en/media/20141119_morpho-places-first-nist-2014-minex-fingerprint-benchmark">Morpho places first in NIST 2014 MINEX fingerprint benchmark</a></p>
<p>さらに、犯罪現場に残った指紋、いわゆる遺留指紋とデータベースに載っている人間から直接採取した指紋 (押捺指紋) との照合、また他の犯罪現場で採取した別の遺留指紋との照合など、指紋照合と言ってもいろんなパターンがあるわけです。<br>特に遺留指紋は現場に指全体がきれいに残っているなんてあまりなくて、別の指紋と重なっている、一部しか残っていないとかよくある話です。<br>これらの問題を解決する技術をトータルで持っているのが上位三強です。</p>
<p>とはいっても、ニッチな技術で攻めるのは間違っていなくて、AuthenTec社はそれが幸いしてAppleに評価してもらえたわけです。</p>
<h3 id="特徴データ"><a href="#特徴データ" class="headerlink" title="特徴データ"></a>特徴データ</h3><p>さて、指紋、掌紋、足紋でも、他でもそうですが、採取した生体情報から、その生体情報を特徴付ける情報のみを抽出してデータ化します。<br>これを特徴データと呼んでいますが、指紋の場合、そのなかに特徴点 (Minutia) と呼ばれるものがあります。<br>特徴点が12個一致すれば、照合上、同一指紋とみなすことができます。<br>また、指紋においては、隆線 (芯線:Skeleton)も大事なデータですが、指紋の紋様自体も重要です。</p>
<h3 id="紋様"><a href="#紋様" class="headerlink" title="紋様"></a>紋様</h3><p>紋様には様々な種類がありますが、人種によって、紋様毎の発現率が異なります。下記はその一例です。実際はもっと種類があります。</p>
<table>
<thead>
<tr>
<th align="left">和名</th>
<th align="left">英語</th>
<th align="left">略</th>
</tr>
</thead>
<tbody><tr>
<td align="left">渦状紋</td>
<td align="left">Whorls</td>
<td align="left">W</td>
</tr>
<tr>
<td align="left">弓状紋</td>
<td align="left">Arch</td>
<td align="left">A</td>
</tr>
<tr>
<td align="left">蹄状紋</td>
<td align="left">Loops</td>
<td align="left">L</td>
</tr>
<tr>
<td align="left">突起弓状紋</td>
<td align="left">Tented Arch</td>
<td align="left">T</td>
</tr>
<tr>
<td align="left">側蹄状紋</td>
<td align="left">Right Loop</td>
<td align="left">R</td>
</tr>
</tbody></table>
<p><a href="../../../../public/2016/04/Patterns.png"><img src="../../../../public/2016/04/Patterns-1024x229.png"></a><br>紋様の一例</p>
<p>前置きが長くなりましたが、これらの紋様をディープラーニングで分類してみましょう。</p>
<h1 id="準備1"><a href="#準備1" class="headerlink" title="準備1"></a>準備1</h1><p>今回、DeepLearningのために、<strong>GeForce GTX 750 Ti</strong>を入手しました。<br>というわけで、Caffeのビルド設定を変更します。<br>Pythonは有効にし、<strong>CpuOnlyBuild</strong>をfalse、<strong>UseCuDNN</strong>をtrueにします。</p>
<p>特に重要なのが、<strong>CudaArchitecture</strong>です。<br>GTX 750 TiのCompute Capabilityは5.0なので、<strong>compute_50,sm_50</strong>を設定します。</p>
<p>以上で、ソリューションをリビルドします。</p>
<h1 id="準備2"><a href="#準備2" class="headerlink" title="準備2"></a>準備2</h1><p>次にデータですが、NISTが指紋データを教師情報と一緒に公開しています。<br>こんなの日本じゃありえません。素晴らしい。<br>下記からダウンロードできます。ただし、接続の調子が悪いのかタイムアウトすることが多々あります。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.nist.gov/srd/nistsd4.cfm">Special Database 4 - NIST 8-bit Gray Scale Images of Fingerprint Image Groups.</a></li>
<li><a target="_blank" rel="noopener" href="http://www.nist.gov/srd/nistsd9.cfm">Special Database 9 - NIST 8-bit Gray Scale Images of Mated Fingerprint Card Pairs.</a></li>
<li><a target="_blank" rel="noopener" href="http://www.nist.gov/srd/nistsd14.cfm">NIST Mated Fingerprint Card Pairs 2. Has 2,700 ten-print card pairs of rolled fingerprints (no plain impressions).</a></li>
</ul>
<p>今回は、Special Database4を使います。4,9,14は無料ですが、他は有料だったりします。</p>
<p>入手したファイルを解凍すると、下記のような構成になっています。</p>
<ul>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_0</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_1</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_2</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_3</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_4</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_5</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_6</li>
<li>NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_7</li>
</ul>
<p>各フォルダ内にpngとtxtファイルが500個ずつ含まれています。<br>学習にはfigs_0からfigs_6の3500枚の画像を使います。テストにはfigs_7を使います。</p>
<p>さて、データを見ていると指紋画像のサイズが512x512であることに気がつくと思います。<br>指紋認証の世界では512x512の500ppi (pixel per inch) が常識です。1000ppiもあります。<br>txtには、性別、紋様種別が含まれています。<br>このデータ群の紋様種別は、Whorls、Arch、Loops、Tented Arch、Right Loopの5種です。</p>
<p>これらを使って、画像のデータベース作成、学習、テスト、分類を実行します。<br>これら一連の流れを自動化したバッチを用意しました。</p>
<div class="blog-card"><div class="hbc-link-wrap"><a class="hbc-link" href="https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1" target="_blank" rel="nofollow"><div class="hbc-card"><div class="hbc-info"><img class="hbc-favicon" src="http://www.google.com/s2/favicons?domain=github.com"></img><div class="hbc-site-name">GitHub</div></div><div class="hbc-contents"><div class="hbc-thumbnail"><img src="https://opengraph.githubassets.com/6e34bb044ff5d3fa321406fe7896c23965ec69a78fd5dc22693428c1b469e00c/takuya-takeuchi/Demo"></img></div><div class="hbc-text"><div class="hbc-title">Demo/Caffe1 at master · takuya-takeuchi/Demo</div><div class="hbc-url">https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1</div><div class="hbc-description">Sample source code for Demonstration, Experiment and Test - Demo/Caffe1 at master · takuya-takeuchi/Demo</div></div></div></div></a></div></div>

<p>これらを、png_txtフォルダ直下に展開し、下記の2点を修正します。</p>
<h2 id="0-SetEnv-bat"><a href="#0-SetEnv-bat" class="headerlink" title="0.SetEnv.bat"></a>0.SetEnv.bat</h2><p><strong>CAFFE_ROOT</strong>、<strong>MINICONDA</strong>、<strong>ROOTFOLDER</strong>を環境に応じて変更します。</p>
<h2 id="io-py"><a href="#io-py" class="headerlink" title="io.py"></a>io.py</h2><p>今回の実験では、入力画像を8bitにして扱うことでメモリ消費量を削減しているのですが、PythonのCaffeモジュールが8bit画像として、画像を入力できないため、ネットワークと入力データの整合性がとれません。<br>そのため、<strong>7.Classify.bat</strong>を使うときだけ、<strong>&lt;Miniconda2_root&gt;\Lib\site-packages\caffe\io.py</strong>を修正します。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">- def load_image(filename, color=True):</span></span><br><span class="line"><span class="addition">+ def load_image(filename, color=False):</span></span><br></pre></td></tr></table></figure>

<p>と直します。<br>これで準備完了です。</p>
<h1 id="実験"><a href="#実験" class="headerlink" title="実験"></a>実験</h1><p>バッチを1から順に実行します。GPUを使えるなら、</p>
<ul>
<li>1.CreateListFile.ps1</li>
<li>2.CreateDatabase.bat</li>
<li>3.MeanDatabase.bat</li>
<li>4.Train_GPU.bat</li>
<li>7.Classify.bat</li>
</ul>
<p>とコマンドプロンプトまたはPowerShellで順番に実行します。<br>ただし、<strong>7.Classify.bat</strong>は引数に画像ファイルを指定します。<br>例えば、</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">7</span>.Classify.bat &quot;D:\Works\NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_7\f1752_04.png&quot;</span><br></pre></td></tr></table></figure>

<p>のような感じです。<br><strong>4.Train_GPU.bat</strong>を実行することで、学習とテストを同時に実行します。<br>その結果、精度を表すAccuracyが10%弱が、最終的に約80%まで向上していることがわかります。3500回の学習で10分くらいでした。</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">I0623 <span class="number">00</span>:<span class="number">35</span>:<span class="number">05</span>.<span class="number">288350</span>  <span class="number">6908</span> solver.cpp:<span class="number">337</span>] Iteration <span class="number">0</span>, Testing <span class="built_in">net</span> (#<span class="number">0</span>)</span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">35</span>:<span class="number">07</span>.<span class="number">777075</span>  <span class="number">6908</span> blocking_queue.cpp:<span class="number">50</span>] Data layer prefetch queue empty</span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">35</span>:<span class="number">09</span>.<span class="number">379405</span>  <span class="number">6908</span> solver.cpp:<span class="number">404</span>]     Test <span class="built_in">net</span> output #<span class="number">0</span>: accuracy = <span class="number">0</span>.<span class="number">148</span></span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">35</span>:<span class="number">09</span>.<span class="number">382393</span>  <span class="number">6908</span> solver.cpp:<span class="number">404</span>]     Test <span class="built_in">net</span> output #<span class="number">1</span>: loss = <span class="number">1</span>.<span class="number">61361</span> (* <span class="number">1</span> = <span class="number">1</span>.<span class="number">61361</span> loss)</span><br></pre></td></tr></table></figure>

<p>が</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">I0623 <span class="number">00</span>:<span class="number">49</span>:<span class="number">38</span>.<span class="number">984040</span>  <span class="number">6908</span> solver.cpp:<span class="number">317</span>] Iteration <span class="number">3500</span>, loss = <span class="number">0</span>.<span class="number">304031</span></span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">49</span>:<span class="number">38</span>.<span class="number">986039</span>  <span class="number">6908</span> solver.cpp:<span class="number">337</span>] Iteration <span class="number">3500</span>, Testing <span class="built_in">net</span> (#<span class="number">0</span>)</span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">49</span>:<span class="number">42</span>.<span class="number">858041</span>  <span class="number">6908</span> solver.cpp:<span class="number">404</span>]     Test <span class="built_in">net</span> output #<span class="number">0</span>: accuracy = <span class="number">0</span>.<span class="number">788</span></span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">49</span>:<span class="number">42</span>.<span class="number">860039</span>  <span class="number">6908</span> solver.cpp:<span class="number">404</span>]     Test <span class="built_in">net</span> output #<span class="number">1</span>: loss = <span class="number">0</span>.<span class="number">465629</span> (* <span class="number">1</span> = <span class="number">0</span>.<span class="number">465629</span> loss)</span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">49</span>:<span class="number">42</span>.<span class="number">864039</span>  <span class="number">6908</span> solver.cpp:<span class="number">322</span>] Optimization Done.</span><br><span class="line">I0623 <span class="number">00</span>:<span class="number">49</span>:<span class="number">42</span>.<span class="number">869042</span>  <span class="number">6908</span> caffe.cpp:<span class="number">223</span>] Optimization Done.</span><br></pre></td></tr></table></figure>

<p>になります。<br>しかし、これでは、本当に正しく学習できるいるのかいまいちわからないため、<strong>7.Classify.bat</strong>に学習に使った画像以外 (今回はfigs_7) から一枚を選んで、引数として渡して実行します。<br>結果として、f1751_08.pngの場合、</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Loading file: D:\Works\NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_7\f1751_08.png</span><br><span class="line">Classifying <span class="number">1</span> inputs.</span><br><span class="line">Done <span class="keyword">in</span> <span class="number">0</span>.<span class="number">22</span> s.</span><br><span class="line">Saving results into output.npy</span><br><span class="line">#<span class="number">1</span> | <span class="number">3</span> T | <span class="number">84</span>.<span class="number">0</span>%</span><br><span class="line">#<span class="number">2</span> | <span class="number">2</span> R | <span class="number">11</span>.<span class="number">8</span>%</span><br><span class="line">#<span class="number">3</span> | <span class="number">0</span> A |  <span class="number">2</span>.<span class="number">1</span>%</span><br></pre></td></tr></table></figure>

<p>T (Tented Arch) が一番高い確率を出力してます。画像に対応するテキストファイル </p>
<ul>
<li>Gender: M</li>
<li>Class: T</li>
<li>History: f1751_08.pct TA a2618.pct</li>
</ul>
<p>と見比べると、一致していることがわかります。</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>DeepLearningのネタは結構転がっていますが、指紋を使った実験はweb上では無いと思います。<br>既に論文でDeepLearningでの紋様分類は存在しましたが、外国の論文でした。<br>日本語としての記事としてはなかなかレアではないでしょうか？</p>
<h1 id="Source-Code"><a href="#Source-Code" class="headerlink" title="Source Code"></a>Source Code</h1><p><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1">https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2016-06-23</span><i class="fa fa-tag"></i><a class="tag" href="/categories/Microsoft/" title="Microsoft">Microsoft </a><a class="tag" href="/categories/ディープラーニング/" title="ディープラーニング">ディープラーニング </a><a class="tag" href="/categories/オープンソース/" title="オープンソース">オープンソース </a><a class="tag" href="/categories/ディープラーニング/Caffe/" title="Caffe">Caffe </a><a class="tag" href="/categories/Windows/" title="Windows">Windows </a><a class="tag" href="/categories/指掌紋/" title="指掌紋">指掌紋 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://takuya-takeuchi.github.io/2016/06/23/1140/,A certain engineer &quot;COMPLEX&quot;,ディープラーニング Caffe for Windows その2 指紋紋様分類,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2016/07/07/1432/" title="開発メモ その4 AppVeyorの 'Unable to locate' エラーに対応する">前へ</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2016/06/22/1414/" title="開発メモ その3 pipでインストールする先のPython.exeを指定する">次へ</a></li></ul></div></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/search.js"></script></body></html>