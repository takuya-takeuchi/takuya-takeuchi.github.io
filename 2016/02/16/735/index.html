<!DOCTYPE html><html lang="ja-JP"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Core"><title>.NETでGPUPUを試してみる CUDA編 第2回 · A certain engineer "COMPLEX"</title><meta name="description" content="前回はCUDAの性能がとんでもなく悪かったです。

Introduction明らかに悪い、とは思っていたけどここまで悪いとは思っていませんでした。 いや本当。 今回は、CUDAの仕組みから。
ExplanationCUDAってどうやって動いている？今さらですが。 CUDAはGPUを使って計算します。"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/hexo-tag-blog-card.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.1.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">A certain engineer &quot;COMPLEX&quot;</a></h3><div class="description"><p>とある技術者の劣等感</p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi"><i class="fa fa-github"></i></a></li><li><a target="_blank" rel="noopener" href="https://twitter.com/takuya_takeuchi"><i class="fa fa-twitter-square"></i></a></li><li><a target="_blank" rel="noopener" href="https://www.facebook.com/takuya.takeuchi.sns"><i class="fa fa-facebook-square"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2020 </span><i class="fa fa-star"></i><span> Core</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="search"><div class="text"><input placeholder="検索ワードを入力してください" id="search-text" onkeypress="javascript:search(event)"></div><div class="btn"><a><i class="fa fa-search"></i></a></div></div><div class="nav"><li><a href="/">ホーム</a></li><li><a href="/archives">アーカイブ</a></li><li><a href="/tags">タグ</a></li><li><a href="/about">自己紹介</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>.NETでGPUPUを試してみる CUDA編 第2回</a></h3></div><div class="post-content"><p><a target="_blank" rel="noopener" href="http://wp.me/p7138e-bI">前回</a>はCUDAの性能がとんでもなく悪かったです。</p>
<a id="more"></a>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>明らかに悪い、とは思っていたけどここまで悪いとは思っていませんでした。 いや本当。 今回は、CUDAの仕組みから。</p>
<h1 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h1><h2 id="CUDAってどうやって動いている？"><a href="#CUDAってどうやって動いている？" class="headerlink" title="CUDAってどうやって動いている？"></a>CUDAってどうやって動いている？</h2><p>今さらですが。 CUDAはGPUを使って計算します。 が、ここで理解してほしいのは、そういう計算処理は本来、CPUがやることで、GPUに計算させているのはあくまでおまけ。 で、当然ながら、現在のPCの仕組み上、GPUとCPUには扱いに大きな差があります。 まず、CPUとメモリの間はレジスタとキャッシュ (1次とか2次とか)が備わっています。 これによりデータやプログラムが可能な限り再利用され、データの移動が最小限になります。 が、GPUとCPU側のメモリの間にそんなものはありません。 たしかに、GPUにはメモリが乗っていますけど、そこにプログラムが使っているデータはありません。 そもそもメモリ (要するにDRAM) はCPUの側に比べれば格段に遅い。 なので、プログラムからGPUに処理を任せるときは、データとプログラムを渡す必要があります。 これ大事。 で、先に話したように、GPUとプログラムの距離は非常に遠い、つまり遅いです。 そもそもDRAMの演算装置間の転送速度は遅いのに、CPU側のメモリとGPUではさらに遅い。 以上を踏まえると、<strong>命令やデータをCPU側メモリからGPUに何度も転送するのは最悪</strong>、ということです。 で、ここまで書いてあれですが、きちんと用語があって、CPU側のメモリ、とかいう表現はしません。</p>
<p>Term</p>
<p>Meaning</p>
<p>ホスト</p>
<p>呼び出し側。CPU・プログラムと思ってくれれば。</p>
<p>デバイス</p>
<p>GPU側</p>
<p>カーネル</p>
<p>デバイス上で実行される処理。ホスト上のソースコードに書かれたデバイス用の処理</p>
<p>と定義されています。 もう一度言いますと、<strong>ホストとデバイス間のカーネルやデータの転送は最小限にする</strong>、ってことです。</p>
<h2 id="CUDAの真の実力"><a href="#CUDAの真の実力" class="headerlink" title="CUDAの真の実力"></a>CUDAの真の実力</h2><p>前段を踏まえて前回のプログラムの問題点を検証します。 まずデバイス側のカーネルは [code lang=”cpp”] __global__ void addKernel(int *c, const int *a, const int *b) { int i = threadIdx.x; c[i] = a[i] + b[i]; } [/code] になります。 CUDAプログラミングにおいて、関数がホスト側、デバイス側で実行されるかどうかの識別は下記の3つの関数修飾子で区別します。 <strong>__global__</strong> デバイス側で実行される、ホスト側から呼び出される関数であることを示します。戻り値は必ずvoidです。 <strong>__device__</strong> デバイス側で実行され、デバイス側から呼び出される関数であることを示します。要するに、デバイス側のprivateな関数。 <strong>__host__</strong> ホスト側で実行され、ホスト側から呼び出される関数であることを示します。要するに、ホスト側のprivateな関数。</p>
<p>それで、上の <strong>addKernel 関数</strong> は、<strong>global</strong>なので、デバイス側で実行され、ホスト側でコールされます。 この関数は、別に定義された <strong>cudaError_t addWithCuda(int *, const int *, const int *, unsigned int) 関数</strong> で呼ばれます。 前のコードでは、この addWithCuda 関数を10000回呼び出していました。すなわち10000回、カーネルとデータをデバイス間に転送していたことになります。 それは遅いに決まっています。 理想的なのは、デバイス側で10000回処理が実行されることです。</p>
<p>×　デバイス側に処理を10000回依頼する ○　デバイス側で処理を10000回実行する</p>
<p>ということです。 以上を踏まえコードを修正します。 サンプルコードはページの末尾を参照。 変更点は</p>
<ul>
<li>ループ回数を10000から100000000回に変更</li>
<li>addKernel 関数内でループを回すように変更</li>
<li>デバイス側の計測は addWithCuda 関数内で実行するよう変更</li>
<li>変数a,b,cはconstを外して、可変長に変更</li>
</ul>
<p>これだと、ループ回数は配列長*ループ回数なので、5億回になります。 これを実行させます。 [code lang=”sh”] CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {5556} No CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {0} [/code] 一気に改善しています。ですが、まだダメです。 というか、CPUが速すぎる気がします。 そこで、デバイス側をコメントアウトして、ホスト側だけの計測をしました。 その結果、ループ回数10億、配列長50で8000-9000msという結果が出ました。 少なくとも、計測処理は正しいことがわかりました。常に0になるとか、そういうのはない。 なので、ループ回数を1億にして、配列長50なら800-900msになるはず。 ループ回数が変化なし、配列長が10倍なら、CUDAはおよそ55000msになるはず。</p>
<h2 id="GPUの特性"><a href="#GPUの特性" class="headerlink" title="GPUの特性"></a>GPUの特性</h2><p>はい。 結果はそうなりませんでした。 [code lang=”sh”] CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {5555} No CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {856} [/code] CPUの計算量推定は正しかったのですが、GPUはそうなりませんでした。 結論を言えば、並列化が関係してます。 <strong>addKernel 関数</strong> をみると、<strong>threadIdx</strong> なるオブジェクトがいます。 [code lang=”cpp”] __global__ void addKernel(int *c, const int *a, const int *b, const int loop) { int i = threadIdx.x; for (unsigned int t = 0; t &lt; loop; ++t) { c[i] = a[i] + b[i]; } } [/code] これなんでしょう。 これ、<strong>NVIDIA GPU Computing Toolkit\CUDA\v7.5\include\device_launch_parameters.h</strong> に定義されています。 字面からみればスレッドIDです。 <strong>CUDA_C_Programming_Guide.pdf</strong> がありますのでそれを見ます。</p>
<blockquote>
<p>B.4.4. threadIdx This variable is of type uint3 (see char, short, int, long, longlong, float, double ) and contains the thread index within the block.</p>
</blockquote>
<p>[code] 訳: B.4.4. threadIdx この変数はuint3 (char, short, int, long, longlong, float, double) 型であり、ブロック内のスレッドインデックスです。 [/code] とあります。 字面の通りということでしょう。 だとするならば、CUDAはスレッド処理を実行しているはずです。ゆえに、CPUのような計算量推測ができなかったのでしょう。 では、どこでスレッドの起動を指定しているのか、というと [code lang=”cpp”] // Launch a kernel on the GPU with one thread for each element. addKernel &lt;&lt; &lt;1, size &gt;&gt; &gt;(dev_c, dev_a, dev_b, g_loop); [/code] の <strong>&lt;1, size &gt;</strong> とのこと。 これは、1ブロックにつき最大sizeスレッドで関数を実行せよ、という意味らしい。 <a target="_blank" rel="noopener" href="http://www.gdep.jp/page/view/253">第6回　CUDAプログラミングモデル①</a>によれば、指定できるスレッド数は512が限界とのこと。 なので、現在sizeは配列長さと等しい。 つまり、配列の 1 要素に対して、1スレッドで動作するため、配列長さを10倍にしても、処理時間が変化しなかったのである。 ともすれば、GPUはCPUのスピードにはかなわないが、大量のスレッドでその分作業をこなすことで、高速化を図るしか道がないことになる。 なので、CPUは単純に配列長に比例し、GPUは配列長の影響を受けないので、配列帳が7-8倍になれば、ホストとデバイスの処理結果が近似または逆転するはずである。 試しに配列長を400にしてみた。 (倍数+1しないと一致しないはず) [code lang=”sh”] CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {5778} No CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {5295} [/code] 思い切って512にしてみる。 [code lang=”sh”] CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {7489} No CUDA is {1,2,3,4,5} + {10,20,30,40,50} = {11,22,33,44,55} time = {6686} [/code] 追いつかない…</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>なんで、CUDAがとてつもなく遅かったのかは原因がつかめました。 が、期待した速度が出ていないこともまた事実。 次回は、もう少し原因を探っていきたいです。</p>
<h1 id="Source-Code"><a href="#Source-Code" class="headerlink" title="Source Code"></a>Source Code</h1><p><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi/Demo/tree/master/CUDA2">https://github.com/takuya-takeuchi/Demo/tree/master/CUDA2</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2016-02-16</span><i class="fa fa-tag"></i><a class="tag" href="/categories/Microsoft/" title="Microsoft">Microsoft </a><a class="tag" href="/categories/Microsoft/NET-Framework/" title=".NET Framework">.NET Framework </a><a class="tag" href="/categories/net-framework/" title="net-framework">net-framework </a><a class="tag" href="/categories/ソフトウェア紹介/" title="ソフトウェア紹介">ソフトウェア紹介 </a><a class="tag" href="/categories/net-framework/NETで○○○を試してみる/" title=".NETで○○○を試してみる">.NETで○○○を試してみる </a><a class="tag" href="/categories/gpupu/" title="gpupu">gpupu </a><a class="tag" href="/categories/gpupu/CUDA/" title="CUDA">CUDA </a><a class="tag" href="/categories/GPUPU/" title="GPUPU">GPUPU </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://takuya-takeuchi.github.io/2016/02/16/735/,A certain engineer &quot;COMPLEX&quot;,.NETでGPUPUを試してみる CUDA編 第2回,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2016/02/20/808/" title="ディープラーニング Caffe その1 環境構築">前へ</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2016/02/14/726/" title=".NETでGPUPUを試してみる CUDA編 第1回">次へ</a></li></ul></div></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/search.js"></script></body></html>