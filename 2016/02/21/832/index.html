<!DOCTYPE html><html lang="ja-JP"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Core"><title>ディープラーニング Caffe その2 テスト · A certain engineer "COMPLEX"</title><meta name="description" content="前回はHyper-V上に作成したUbuntu上にcaffeをインストールしました。今回は実際に使ってみます。

概要caffeは大まかに下記の手順で実施します。

データセットの用意
データの格納
パラメータの調整
学習
評価

今回は、学習が完了した状態で、評価を行います。 ちなみに、データセット"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/hexo-tag-blog-card.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.1.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">A certain engineer &quot;COMPLEX&quot;</a></h3><div class="description"><p>とある技術者の劣等感</p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi"><i class="fa fa-github"></i></a></li><li><a target="_blank" rel="noopener" href="https://twitter.com/takuya_takeuchi"><i class="fa fa-twitter-square"></i></a></li><li><a target="_blank" rel="noopener" href="https://www.facebook.com/takuya.takeuchi.sns"><i class="fa fa-facebook-square"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2020 </span><i class="fa fa-star"></i><span> Core</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="search"><div class="text"><input placeholder="検索ワードを入力してください" id="search-text" onkeypress="javascript:search(event)"></div><div class="btn"><a><i class="fa fa-search"></i></a></div></div><div class="nav"><li><a href="/">ホーム</a></li><li><a href="/archives">アーカイブ</a></li><li><a href="/tags">タグ</a></li><li><a href="/about">自己紹介</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>ディープラーニング Caffe その2 テスト</a></h3></div><div class="post-content"><p><a target="_blank" rel="noopener" href="http://wp.me/p7138e-d2">前回</a>はHyper-V上に作成したUbuntu上にcaffeをインストールしました。今回は実際に使ってみます。</p>
<a id="more"></a>
<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>caffeは大まかに下記の手順で実施します。</p>
<ol>
<li>データセットの用意</li>
<li>データの格納</li>
<li>パラメータの調整</li>
<li>学習</li>
<li>評価</li>
</ol>
<p>今回は、学習が完了した状態で、評価を行います。 ちなみに、データセットとは、<strong>学習(訓練)用</strong>、<strong>評価用</strong>の2種から構成されるデータ群です。 通常、学習する際に使用したデータを、検証用に使うことはできません。 学生のテストで試験範囲発表で問題そのものが公開されるわけではないのと同じです。学生を「テスト」する意味がないですから。 また、今回のテストはあらかじめ用意されているものを使います。 ネット上で解説されているものと同じですが、他と違うのは、きちんと説明を加えます。 何をしているのかよくわからないし、「おまじない」的な説明は極力避けます。</p>
<h1 id="準備"><a href="#準備" class="headerlink" title="準備"></a>準備</h1><h2 id="モデルの取得"><a href="#モデルの取得" class="headerlink" title="モデルの取得"></a>モデルの取得</h2><p>モデルとは、どういう手順、経路、方法でデータの学習を行うかを定義した多層ニューラルネットワークを指す。 モデルは、<strong>Caffe Model Zoo</strong>というCaffeの学習済モデルを公開したWikiがあり、そこで有力なモデルが公開されている。 下記のコマンドを実行します。caffeのフォルダは前回と同様であるものとします。 必要に応じてsudoするなりします。 [code lang=”sh”] cd /usr/local/caffe/ python scripts/download_model_binary.py models/bvlc_reference_caffenet [/code] 実行したスクリプトは大量のデータ (233MB) をダウンロードしますので時間がかかります。</p>
<h2 id="関連データの取得"><a href="#関連データの取得" class="headerlink" title="関連データの取得"></a>関連データの取得</h2><p>ilsvrc12の学習、評価に用いられる画像ファイル名の一覧、ラベル一覧などをダウンロードします。 [code lang=”sh”] cd /usr/local/caffe/data/ilsvrc12/ chmod u+x get_ilsvrc_aux.sh ./get_ilsvrc_aux.sh [/code]</p>
<h2 id="画像データの取得"><a href="#画像データの取得" class="headerlink" title="画像データの取得"></a>画像データの取得</h2><p>検証に用いる画像のデータセット<a target="_blank" rel="noopener" href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/">Caltech 101</a>をダウンロードします。 ダウンロード先は任意です。 126MBあるので、これも時間がかかります。 [code lang=”sh”] cd /usr/local/caffe/ mkdir dataset cd dataset mkdir caltech101 wget <a target="_blank" rel="noopener" href="http://www.vision.caltech.edu/Image/_Datasets/Caltech101/101/_ObjectCategories.tar.gz">http://www.vision.caltech.edu/Image\_Datasets/Caltech101/101\_ObjectCategories.tar.gz</a> tar xf 101_ObjectCategories.tar.gz [/code] これで準備完了です。</p>
<h1 id="検証"><a href="#検証" class="headerlink" title="検証"></a>検証</h1><h2 id="分類"><a href="#分類" class="headerlink" title="分類"></a>分類</h2><p>実際に画像を入力して分類してみます。 前提として、pycaffeをコンパイル済みであるものとします。 [code lang=”sh”] cd /usr/local/caffe/python python classify.py –raw_scale 255 /usr/local/caffe/dataset/caltech101/101_ObjectCategories/airplanes/image_0001.jpg /usr/local/caffe/dataset/caltech101/result.npy cd /usr/local/caffe/dataset/caltech101/ [/code] <strong>classify.py</strong> によれば、 [code lang=”python”] #!/usr/bin/env python “”” classify.py is an out-of-the-box image classifer callable from the command line.<br>By default it configures and runs the Caffe reference ImageNet model. “”” import numpy as np import os import sys import argparse import glob import time<br>import caffe<br>def main(argv): pycaffe_dir = os.path.dirname(__file__)<br>parser = argparse.ArgumentParser() # Required arguments: input and output files. parser.add_argument( “input_file”, help=”Input image, directory, or npy.” ) parser.add_argument( “output_file”, help=”Output npy filename.” ) # Optional arguments. parser.add_argument( “–model_def”, default=os.path.join(pycaffe_dir, “../models/bvlc_reference_caffenet/deploy.prototxt”), help=”Model definition file.” ) parser.add_argument( “–pretrained_model”, default=os.path.join(pycaffe_dir, “../models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel”), help=”Trained model weights file.” ) parser.add_argument( “–gpu”, action=’store_true’, help=”Switch for gpu computation.” ) parser.add_argument( “–center_only”, action=’store_true’, help=”Switch for prediction from center crop alone instead of “ + “averaging predictions across crops (default).” ) parser.add_argument( “–images_dim”, default=’256,256’, help=”Canonical ‘height,width’ dimensions of input images.” ) parser.add_argument( “–mean_file”, default=os.path.join(pycaffe_dir, ‘caffe/imagenet/ilsvrc_2012_mean.npy’), help=”Data set image mean of [Channels x Height x Width] dimensions “ + “(numpy array). Set to ‘’ for no mean subtraction.” ) parser.add_argument( “–input_scale”, type=float, help=”Multiply input features by this scale to finish preprocessing.” ) parser.add_argument( “–raw_scale”, type=float, default=255.0, help=”Multiply raw input by this scale before preprocessing.” ) parser.add_argument( “–channel_swap”, default=’2,1,0’, help=”Order to permute input channels. The default converts “ + “RGB -&gt; BGR since BGR is the Caffe default by way of OpenCV.” ) parser.add_argument( “–ext”, default=’jpg’, help=”Image file extension to take as input when a directory “ + “is given as the input file.” ) args = parser.parse_args()<br>image_dims = [int(s) for s in args.images_dim.split(‘,’)]<br>mean, channel_swap = None, None if args.mean_file: mean = np.load(args.mean_file) if args.channel_swap: channel_swap = [int(s) for s in args.channel_swap.split(‘,’)]<br>if args.gpu: caffe.set_mode_gpu() print(“GPU mode”) else: caffe.set_mode_cpu() print(“CPU mode”)<br># Make classifier. classifier = caffe.Classifier(args.model_def, args.pretrained_model, image_dims=image_dims, mean=mean, input_scale=args.input_scale, raw_scale=args.raw_scale, channel_swap=channel_swap)<br># Load numpy array (.npy), directory glob (*.jpg), or image file. args.input_file = os.path.expanduser(args.input_file) if args.input_file.endswith(‘npy’): print(“Loading file: %s” % args.input_file) inputs = np.load(args.input_file) elif os.path.isdir(args.input_file): print(“Loading folder: %s” % args.input_file) inputs =[caffe.io.load_image(im_f) for im_f in glob.glob(args.input_file + ‘/*.’ + args.ext)] else: print(“Loading file: %s” % args.input_file) inputs = [caffe.io.load_image(args.input_file)]<br>print(“Classifying %d inputs.” % len(inputs))<br># Classify. start = time.time() predictions = classifier.predict(inputs, not args.center_only) print(“Done in %.2f s.” % (time.time() - start))<br># Save print(“Saving results into %s” % args.output_file) np.save(args.output_file, predictions)<br>if __name__ == ‘__main__‘: main(sys.argv) [/code] とあります。 入力と出力は必須なので、最後の2つが入力画像と出力になります。 出力はnumpy標準のファイル形式です。 <strong>--raw_scale 255</strong> は、前処理の前にこのスケール値だけ乗算するとあります。 <a target="_blank" rel="noopener" href="http://iwaki2009.blogspot.jp/2014/12/caffeimagenet.html">OpenCV 備忘録</a> によれば、入力値[0:1]をImageNetモデルの[0:255]に変更するとのこと。 実行後、うまくいって結果を確認、できません。 無慈悲なエラーが出ます。 <a href="../../../../public/2016/02/1-4.png"><img src="../../../../public/2016/02/1-4-300x225.png" alt="無慈悲なエラー"></a></p>
<p>[code lang=”sh”] File “classify.py”, line 138, in main(sys.argv) File “classify.py”, line 110, in main channel_swap=channel_swap) File “/usr/local/caffe/python/caffe/classifier.py”, line 34, in __init__ self.transformer.set_mean(in_, mean) File “/usr/local/caffe/python/caffe/io.py”, line 258, in set_mean raise ValueError(‘Mean shape incompatible with input shape.’) [/code] イラっとしますが、解析すると、*<em>/usr/local/caffe/python/caffe/io.py** の258行目が例外を投げているように見えます。 Google先生に聞いてみると<a target="_blank" rel="noopener" href="http://qiita.com/Bonnnou_108/items/41e6dadeff1310b4eb5d">OSX10.10でCaffeをインストール、リファレンスモデルで画像を分類</a>にて回答が。 [code lang=”python”] if ms != self.inputs[in_][1:]: raise ValueError(‘Mean shape incompatible with input shape.’) [/code] を [code lang=”python”] if ms != self.inputs[in_][1:]: print(self.inputs[in_]) in_shape = self.inputs[in_][1:] m_min, m_max = mean.min(), mean.max() normal_mean = (mean - m_min) / (m_max - m_min) mean = resize_image(normal_mean.transpose((1,2,0)),in_shape[1:]).transpose((2,0,1)) \</em> (m_max - m_min) + m_min #raise ValueError(‘Mean shape incompatible with input shape.’) [/code] に直せばよいとのこと。 修正後、再度実行すると、result.npyが出力されたことを示すメッセージが。</p>
<h2 id="結果"><a href="#結果" class="headerlink" title="結果"></a>結果</h2><p>うきうきしながら、result.npyを開くと。 開けません。というかバイナリファイルなのか読めません。 これを人間の目でわかる結果に直す必要があります。 <a target="_blank" rel="noopener" href="http://techblog.yahoo.co.jp/programming/caffe-intro/">Caffeで手軽に画像分類</a>にて、この結果を人間の目でわかる結果に直すスクリプトを公開してくださっています。感謝です。 [code lang=”sh”] cd /usr/local/caffe/python gedit show_result.py [/code] エディタを開いて下記のスクリプトを保存します。 [code lang=”python”] #! /usr/bin/env python # -*- coding: utf-8 -*- import sys, numpy<br>categories = numpy.loadtxt(sys.argv[1], str, delimiter=”\t”) scores = numpy.load(sys.argv[2]) top_k = 3 prediction = zip(scores[0].tolist(), categories) prediction.sort(cmp=lambda x, y: cmp(x[0], y[0]), reverse=True) for rank, (score, name) in enumerate(prediction[:top_k], start=1): print(‘#%d | %s | %4.1f%%’ % (rank, name, score * 100)) [/code] 保存後。、 [code lang=”sh”] cd /usr/local/caffe/python python show_result.py ../data/ilsvrc12/synset_words.txt /usr/local/caffe/dataset/caltech101/result.npy #1 | n04552348 warplane, military plane | 84.8% #2 | n04008634 projectile, missile | 5.5% #3 | n02690373 airliner | 5.1% [/code] という結果が出力されます。 <a href="../../../../public/2016/02/1-5.png"><img src="../../../../public/2016/02/1-5-300x225.png" alt="入力画像"></a></p>
<p>入力画像 <strong>/usr/local/caffe/dataset/caltech101/101_ObjectCategories/airplanes/image_0001.jpg</strong> が戦闘機である確率が84.8%だと判断されました。 素晴らしい。</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>長かったですが、きちんとcaffeが動作する様を確認できました。 次回はモデルを構築できたらな、と思います。</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2016-02-21</span><i class="fa fa-tag"></i><a class="tag" href="/categories/Linux/" title="Linux">Linux </a><a class="tag" href="/categories/linux/" title="linux">linux </a><a class="tag" href="/categories/e3-83-87-e3-82-a3-e3-83-bc-e3-83-97-e3-83-a9-e3-83-bc-e3-83-8b-e3-83-b3-e3-82-b0/" title="%e3%83%87%e3%82%a3%e3%83%bc%e3%83%97%e3%83%a9%e3%83%bc%e3%83%8b%e3%83%b3%e3%82%b0">%e3%83%87%e3%82%a3%e3%83%bc%e3%83%97%e3%83%a9%e3%83%bc%e3%83%8b%e3%83%b3%e3%82%b0 </a><a class="tag" href="/categories/オープンソース/" title="オープンソース">オープンソース </a><a class="tag" href="/categories/e3-83-87-e3-82-a3-e3-83-bc-e3-83-97-e3-83-a9-e3-83-bc-e3-83-8b-e3-83-b3-e3-82-b0/Caffe/" title="Caffe">Caffe </a><a class="tag" href="/categories/linux/Ubuntu/" title="Ubuntu">Ubuntu </a><a class="tag" href="/categories/ディープラーニング/" title="ディープラーニング">ディープラーニング </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://takuya-takeuchi.github.io/2016/02/21/832/,A certain engineer &quot;COMPLEX&quot;,ディープラーニング Caffe その2 テスト,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2016/02/27/845/" title="ディープラーニング CNTK その1 環境構築">前へ</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2016/02/20/808/" title="ディープラーニング Caffe その1 環境構築">次へ</a></li></ul></div></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/search.js"></script></body></html>