<!DOCTYPE html><html lang="ja-JP"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Core"><title>ディープラーニング CNTK その6 指紋紋様分類 · A certain engineer "COMPLEX"</title><meta name="description" content="前回は評価を可視化してみました。

CNTKが進化しているMicrosoftがフォークさせたCaffeは完成度は高いのですが、2016年5月からメンテナンスが止まっています。 かたや、CNTKは現在進行形でソースが成長してます。 どちらもいい面悪い面があるのですが、CNTKの方がMicrosoftの"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.1.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">A certain engineer &quot;COMPLEX&quot;</a></h3><div class="description"><p>とある技術者の劣等感</p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi"><i class="fa fa-github"></i></a></li><li><a target="_blank" rel="noopener" href="https://twitter.com/takuya_takeuchi"><i class="fa fa-twitter-square"></i></a></li><li><a target="_blank" rel="noopener" href="https://www.facebook.com/takuya.takeuchi.sns"><i class="fa fa-facebook-square"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2020 </span><i class="fa fa-star"></i><span> Core</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">ホーム</a></li><li><a href="/archives">アーカイブ</a></li><li><a href="/tags">タグ</a></li><li><a href="/about">自己紹介</a></li><li><a href="/guestbook">メッセージ</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>ディープラーニング CNTK その6 指紋紋様分類</a></h3></div><div class="post-content"><p><a target="_blank" rel="noopener" href="http://wp.me/p7138e-el">前回</a>は評価を可視化してみました。</p>
<a id="more"></a>
<h1 id="CNTKが進化している"><a href="#CNTKが進化している" class="headerlink" title="CNTKが進化している"></a>CNTKが進化している</h1><p>MicrosoftがフォークさせたCaffeは完成度は高いのですが、2016年5月からメンテナンスが止まっています。 かたや、CNTKは現在進行形でソースが成長してます。 どちらもいい面悪い面があるのですが、CNTKの方がMicrosoftの本命でしょう。 なので、前回実施した指紋紋様分類をCNTKで実践してみます。 最近のCNTKの進化に追随しなければなりません。</p>
<h1 id="準備"><a href="#準備" class="headerlink" title="準備"></a>準備</h1><h2 id="設定ファイル"><a href="#設定ファイル" class="headerlink" title="設定ファイル"></a>設定ファイル</h2><p>CNTKファイルです。 </p>


<p>をベースに構築します。 まず、作業ディレクトリを作ります。ここでは、<strong>ROOT</strong>フォルダとします。 ROOTフォルダの下に、一つフォルダを作り、その中に、<strong>AddTop5Layer.mel</strong>, <strong>AlexNet.cntk</strong>, <strong>AlexNet.ndl</strong>, <strong>Macros.ndl</strong> を任意のフォルダに展開します。 このフォルダを<strong>Config</strong>フォルダとします。 次に、AlexNet.cntkを開き、下記の箇所を変更します。 [code] ConfigDir = “$RootDir$” [/code] を [code] ConfigDir = “$RootDir$/Config” [/code] 2カ所ある [code] minibatchSize=128 [/code] を [code] minibatchSize=32 [/code] [code] cropType=”Random” [/code] を [code] cropType=”Center” [/code] 2カ所ある [code] width=224 height=224 channels=3 [/code] を [code] width=224 height=224 channels=3 [/code] [code] cropRatio=0.875 [/code] を [code] cropRatio=0.875 [/code] 2カ所ある [code] meanFile=”$ConfigDir$/ImageNet1K_mean.xml” [/code] を [code] meanFile=”$ConfigDir$/ImageNet1K_mean.xml” [/code] 2カ所ある [code] labels=[ labelDim=1000 ] [/code] を [code] labels=[ labelDim=1000 ] [/code] に変更します。</p>
<h2 id="画像ファイルリスト"><a href="#画像ファイルリスト" class="headerlink" title="画像ファイルリスト"></a>画像ファイルリスト</h2><p>Caffeの画像ファイルリストの記述方法は [code lang=”default”] &lt;カレントディレクトリからの相対パス&gt;&lt;半角スペース&gt;&lt;0オリジンのラベル番号&gt; [/code] でした。 一方、CNTKで、2016年5月に対応した、ファイルリストをサポートするImageReaderの入力形式は [code lang=”default”] &lt;画像のフルパス&gt;&lt;タブ&gt;&lt;0オリジンのラベル番号&gt; [/code] になります。 前回のファイルリストを少し加工して流用できるはずです。 また、これらのファイルリストを <strong>val_map.txt</strong> , <strong>train_map.txt</strong> という名前に変更し、Configフォルダにコピーします。 個人的にはフルパスの方が好感が持てます。 画像そのものは、システム中に一つだけであって、作業ディレクトリからのパスで変化するようでは、使い勝手が悪すぎるので… ImageReaderについての使い方は </p>
<div class="blog-card"><div class="hbc-link-wrap"><a class="hbc-link" href="https://github.com/Microsoft/CNTK/wiki/Image-reader" target="_blank" rel="nofollow"><div class="hbc-card"><div class="hbc-info"><img class="hbc-favicon" src="http://www.google.com/s2/favicons?domain=github.com"></img><div class="hbc-site-name">GitHub</div></div><div class="hbc-contents"><div class="hbc-thumbnail"><img src="https://avatars2.githubusercontent.com/u/6154722?s=400&v=4"></img></div><div class="hbc-text"><div class="hbc-title">microsoft/CNTK</div><div class="hbc-url">https://github.com/Microsoft/CNTK/wiki/Image-reader</div><div class="hbc-description">Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit - microsoft/CNTK</div></div></div></div></a></div></div>

<p>を参考にしてください。 クロップ機能などが独特ですが… 指紋といえば、ごく一部の人間を覗いて全ての人間が手にもっている隆線によって形成される紋様です。 指紋を持っていない人間もごく一部に存在しますが… <strong>iPhone</strong>の<strong>TouchID</strong>で急激に認知度が向上した気がします。 特に日本では、指紋の採取というのは、人権団体とかの声とかプライバシー云々でいまいち悪のレッテルを貼られている感が否めません。 さて、指紋は古くから使われており、個人を識別する徴として、日本では拇印としてよく知られています。 個人を識別するだけなら、指紋以外に、虹彩、静脈、顔が有名です。 他にも掌紋、足紋もあります。</p>
<h3 id="生体認証"><a href="#生体認証" class="headerlink" title="生体認証"></a>生体認証</h3><p>この手の生物に備わる生体の特徴に基づいた認証を<strong>生体認証 (Biometrics)</strong> と呼びます。 指掌紋技術では、たくさんの企業が競争していますが、<strong>3M Cogent (アメリカ)**、</strong>Morpho (フランス)<strong>、</strong>NEC (日本)<strong>が三強です。 ここでいう三強とは、司法機関、入国管理など、大規模システムでの納入実績が大きい企業を指します。 (例えば、ロサンゼルス国際空港では、Morphoの指紋採取機器が入国管理ゲートにありますし、成田空港にはNECの指紋採取機器があります。) iPhoneの場合、</strong>Apple<strong>は</strong>AuthenTec社**を買収して、TouchIDを開発したようですが、これは指紋を読み取る機器の買収がメインだったと思われます。 指紋の採取の場合、光学センサーで読み取るのが主流ですが、AuthenTec社の場合は周波数で読み取るセンサーだったようで、それがiPhoneでの採用に繋がったのでしょう。 ですので、三強にAppleがない、というのは別に悪意があるわけではなく、この三強は、大規模システム、たとえば、数千万の指紋データから瞬時に個人を特定するなどの総合的な技術を持っています。TouchIDの場合、iPhoneに含まれる指紋データは一人のデータでかつ最大10本の指データです。大して大規模システムでは、入力指紋、つまり識別したい指紋1に対して候補となる指紋データは数千万にも上ることもあります。 事実、アメリカ国立標準技術研究所 (National Institute of Standards and Technology, NIST) の指掌紋技術コンテストでは、計測する内容にもよりますが、上位はこの三強が常です。 <a target="_blank" rel="noopener" href="http://jpn.nec.com/press/201408/20140821_02.html">NEC、米国国立標準技術研究所(NIST)の指紋認証技術のベンチマークテストにおいて第1位の評価を獲得</a> <a target="_blank" rel="noopener" href="http://www.morpho.com/en/media/20141119_morpho-places-first-nist-2014-minex-fingerprint-benchmark">Morpho places first in NIST 2014 MINEX fingerprint benchmark</a> さらに、犯罪現場に残った指紋、いわゆる遺留指紋とデータベースに載っている人間から直接採取した指紋 (押捺指紋) との照合、また他の犯罪現場で採取した別の遺留指紋との照合など、指紋照合と言ってもいろんなパターンがあるわけです。 特に遺留指紋は現場に指全体がきれいに残っているなんてあまりなくて、別の指紋と重なっている、一部しか残っていないとかよくある話です。 これらの問題を解決する技術をトータルで持っているのが上位三強です。 とはいっても、ニッチな技術で攻めるのは間違っていなくて、AuthenTec社はそれが幸いしてAppleに評価してもらえたわけです。</p>
<h3 id="特徴データ"><a href="#特徴データ" class="headerlink" title="特徴データ"></a>特徴データ</h3><p>さて、指紋、掌紋、足紋でも、他でもそうですが、採取した生体情報から、その生体情報を特徴付ける情報のみを抽出してデータ化します。 これを特徴データと呼んでいますが、指紋の場合、そのなかに特徴点 (Minutia) と呼ばれるものがあります。 特徴点が12個一致すれば、照合上、同一指紋とみなすことができます。 また、指紋においては、隆線 (芯線:Skeleton)も大事なデータですが、指紋の紋様自体も重要です。</p>
<h3 id="紋様"><a href="#紋様" class="headerlink" title="紋様"></a>紋様</h3><p>紋様には様々な種類がありますが、人種によって、紋様毎の発現率が異なります。下記はその一例です。実際はもっと種類があります。 [table id=23 /]<br><a href="../../../../public/2016/04/Patterns.png"><img src="../../../../public/2016/04/Patterns-1024x229.png"></a></p>
<p>紋様の一例</p>
<p>前置きが長くなりましたが、これらの紋様をディープラーニングで分類してみましょう。</p>
<h1 id="準備1"><a href="#準備1" class="headerlink" title="準備1"></a>準備1</h1><p>今回、DeepLearningのために、<strong>GeForce GTX 750 Ti</strong>を入手しました。 というわけで、Caffeのビルド設定を変更します。 Pythonは有効にし、<strong>CpuOnlyBuild</strong>をfalse、<strong>UseCuDNN</strong>をtrueにします。 特に重要なのが、<strong>CudaArchitecture</strong>です。 GTX 750 TiのCompute Capabilityは5.0なので、<strong>compute_50,sm_50</strong>を設定します。 以上で、ソリューションをリビルドします。</p>
<h1 id="準備2"><a href="#準備2" class="headerlink" title="準備2"></a>準備2</h1><p>次にデータですが、NISTが指紋データを教師情報と一緒に公開しています。 こんなの日本じゃありえません。素晴らしい。 下記からダウンロードできます。ただし、接続の調子が悪いのかタイムアウトすることが多々あります。 <a target="_blank" rel="noopener" href="http://www.nist.gov/srd/nistsd4.cfm">Special Database 4 - NIST 8-bit Gray Scale Images of Fingerprint Image Groups.</a> <a target="_blank" rel="noopener" href="http://www.nist.gov/srd/nistsd9.cfm">Special Database 9 - NIST 8-bit Gray Scale Images of Mated Fingerprint Card Pairs.</a> <a target="_blank" rel="noopener" href="http://www.nist.gov/srd/nistsd14.cfm">NIST Mated Fingerprint Card Pairs 2. Has 2,700 ten-print card pairs of rolled fingerprints (no plain impressions).</a> 今回は、Special Database4を使います。4,9,14は無料ですが、他は有料だったりします。</p>
<p>入手したファイルを解凍すると、下記のような構成になっています。 [code] NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_0 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_1 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_2 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_3 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_4 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_5 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_6 NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_7 [/code] 各フォルダ内にpngとtxtファイルが500個ずつ含まれています。 学習にはfigs_0からfigs_6の3500枚の画像を使います。テストにはfigs_7を使います。 さて、データを見ていると指紋画像のサイズが512x512であることに気がつくと思います。 指紋認証の世界では512x512の500ppi (pixel per inch) が常識です。1000ppiもあります。 txtには、性別、紋様種別が含まれています。 このデータ群の紋様種別は、Whorls、Arch、Loops、Tented Arch、Right Loopの5種です。 これらを使って、画像のデータベース作成、学習、テスト、分類を実行します。 これら一連の流れを自動化したバッチを用意しました。 </p>
<div class="blog-card"><div class="hbc-link-wrap"><a class="hbc-link" href="https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1" target="_blank" rel="nofollow"><div class="hbc-card"><div class="hbc-info"><img class="hbc-favicon" src="http://www.google.com/s2/favicons?domain=github.com"></img><div class="hbc-site-name">GitHub</div></div><div class="hbc-contents"><div class="hbc-thumbnail"><img src="https://avatars0.githubusercontent.com/u/6241854?s=400&v=4"></img></div><div class="hbc-text"><div class="hbc-title">takuya-takeuchi/Demo</div><div class="hbc-url">https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1</div><div class="hbc-description">Sample source code for Demonstration, Experiment and Test - takuya-takeuchi/Demo</div></div></div></div></a></div></div>

<p>これらを、png_txtフォルダ直下に展開し、下記の2点を修正します。</p>
<h2 id="0-SetEnv-bat"><a href="#0-SetEnv-bat" class="headerlink" title="0.SetEnv.bat"></a>0.SetEnv.bat</h2><p><strong>CAFFE_ROOT</strong>、<strong>MINICONDA</strong>、<strong>ROOTFOLDER</strong>を環境に応じて変更します。</p>
<h2 id="io-py"><a href="#io-py" class="headerlink" title="io.py"></a>io.py</h2><p>今回の実験では、入力画像を8bitにして扱うことでメモリ消費量を削減しているのですが、PythonのCaffeモジュールが8bit画像として、画像を入力できないため、ネットワークと入力データの整合性がとれません。 そのため、<strong>7.Classify.bat</strong>を使うときだけ、**&lt;Miniconda2_root&gt;\Lib\site-packages\caffe\io.py**を修正します。 [code lang=”python”] def load_image(filename, color=True): [/code] を [code lang=”python”] def load_image(filename, color=False): [/code] と直します。 これで準備完了です。</p>
<h1 id="実験"><a href="#実験" class="headerlink" title="実験"></a>実験</h1><p>バッチを1から順に実行します。GPUを使えるなら、 <strong>1.CreateListFile.ps1 2.CreateDatabase.bat 3.MeanDatabase.bat 4.Train_GPU.bat 7.Classify.bat</strong> とコマンドプロンプトまたはPowerShellで順番に実行します。 ただし、<strong>7.Classify.bat</strong>は引数に画像ファイルを指定します。 例えば、 [code lang=”batch”] 7.Classify.bat “D:\Works\NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_7\f1752_04.png” [/code] のような感じです。 <strong>4.Train_GPU.bat</strong>を実行することで、学習とテストを同時に実行します。 その結果、精度を表すAccuracyが10%弱が、最終的に約80%まで向上していることがわかります。3500回の学習で10分くらいでした。 [code lang=”batch”] I0623 00:35:05.288350 6908 solver.cpp:337] Iteration 0, Testing net (#0) I0623 00:35:07.777075 6908 blocking_queue.cpp:50] Data layer prefetch queue empty I0623 00:35:09.379405 6908 solver.cpp:404] Test net output #0: accuracy = 0.148 I0623 00:35:09.382393 6908 solver.cpp:404] Test net output #1: loss = 1.61361 (* 1 = 1.61361 loss) [/code] が [code lang=”batch”] I0623 00:49:38.984040 6908 solver.cpp:317] Iteration 3500, loss = 0.304031 I0623 00:49:38.986039 6908 solver.cpp:337] Iteration 3500, Testing net (#0) I0623 00:49:42.858041 6908 solver.cpp:404] Test net output #0: accuracy = 0.788 I0623 00:49:42.860039 6908 solver.cpp:404] Test net output #1: loss = 0.465629 (* 1 = 0.465629 loss) I0623 00:49:42.864039 6908 solver.cpp:322] Optimization Done. I0623 00:49:42.869042 6908 caffe.cpp:223] Optimization Done. [/code] になります。 しかし、これでは、本当に正しく学習できるいるのかいまいちわからないため、<strong>7.Classify.bat</strong>に学習に使った画像以外 (今回はfigs_7) から一枚を選んで、引数として渡して実行します。 結果として、f1751_08.pngの場合、 [code lang=”batch”] Loading file: D:\Works\NISTSpecialDatabase4GrayScaleImagesofFIGS\sd04\png_txt\figs_7\f1751_08.png Classifying 1 inputs. Done in 0.22 s. Saving results into output.npy #1 | 3 T | 84.0% #2 | 2 R | 11.8% #3 | 0 A | 2.1% [/code] T (Tented Arch) が一番高い確率を出力してます。画像に対応するテキストファイル Gender: M Class: T History: f1751_08.pct TA a2618.pct と見比べると、一致していることがわかります。</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>DeepLearningのネタは結構転がっていますが、指紋を使った実験はweb上では無いと思います。 既に論文でDeepLearningでの紋様分類は存在しましたが、外国の論文でした。 日本語としての記事としてはなかなかレアではないでしょうか？</p>
<h1 id="Source-Code"><a href="#Source-Code" class="headerlink" title="Source Code"></a>Source Code</h1><p><a target="_blank" rel="noopener" href="https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1">https://github.com/takuya-takeuchi/Demo/tree/master/Caffe1</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-10-24</span><i class="fa fa-tag"></i><a class="tag" href="/categories/未分類/" title="未分類">未分類 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://takuya-takeuchi.github.io/2018/10/24/1427/,A certain engineer &quot;COMPLEX&quot;,ディープラーニング CNTK その6 指紋紋様分類,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2018/10/28/3343/" title="開発メモ その139 Hyper-Vの詳細な解析ログを取得する">前へ</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/10/22/3221/" title="開発メモ その138 ChainerでDCGANのサンプル実行中に遭遇したエラー">次へ</a></li></ul></div></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script></body></html>